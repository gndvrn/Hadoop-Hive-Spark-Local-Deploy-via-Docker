services:
  postgres:
    image: postgres:13
    container_name: hive-metastore-postgres
    hostname: postgres
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - ./postgres/data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - hadoop-network

  namenode:
    build:
      context: .
      dockerfile: hadoop.Dockerfile
    container_name: namenode
    hostname: namenode
    environment:
      - HADOOP_SSH_OPTS="-o StrictHostKeyChecking=no"
      - HDFS_NAMENODE_USER=${HDFS_NAMENODE_USER}
      - HDFS_DATANODE_USER=${HDFS_DATANODE_USER}
      - HADOOP_USER_NAME=${HADOOP_USER_NAME}
      - HADOOP_CLUSTER_NAME=${HADOOP_CLUSTER_NAME}
      - HDFS_SECONDARYNAMENODE_USER=${HDFS_SECONDARYNAMENODE_USER}
    volumes:
      - ./hadoop/namenode/data:/hadoop/dfs/name
    ports:
      - "9870:9870" # NameNode Web UI
      - "9010:9000" # NameNode RPC
    networks:
      - hadoop-network

  datanode:
    build:
      context: .
      dockerfile: hadoop.Dockerfile
    container_name: datanode
    hostname: datanode
    environment:
      - HDFS_DATANODE_USER=${HDFS_DATANODE_USER}
      - HADOOP_USER_NAME=${HADOOP_USER_NAME}
      - HDFS_SECONDARYNAMENODE_USER=${HDFS_SECONDARYNAMENODE_USER}
      - HADOOP_CLUSTER_NAME=${HADOOP_CLUSTER_NAME}
    volumes:
      - ./hadoop/datanode/data:/hadoop/dfs/data
    ports:
      - "9864:9864" # DataNode Web UI
    networks:
      - hadoop-network

  hive:
    build:
      context: .
      dockerfile: hive.Dockerfile
    container_name: hive-server
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - HDFS_NAMENODE_USER=${HDFS_NAMENODE_USER}
      - HDFS_DATANODE_USER=${HDFS_DATANODE_USER}
      - HDFS_SECONDARYNAMENODE_USER=${HDFS_SECONDARYNAMENODE_USER}
    depends_on:
      - postgres
      - namenode
      - datanode
    ports:
      - "10000:10000" # HiveServer2
      - "10002:10002" # Hive Metastore Thrift
    networks:
      - hadoop-network

  jupyter-pyspark:
    build:
      context: ./jupyter
      dockerfile: Dockerfile
    container_name: jupyter-pyspark
    command: jupyter notebook --no-browser --NotebookApp.token='' --NotebookApp.password='' --ip='*' --allow-root
    environment:
      GRANT_SUDO: "yes"
    volumes:
      - jupyter_data:/home/jovyan
    ports:
      - "8888:8888"
    networks:
      - hadoop-network

networks:
  hadoop-network:
    driver: bridge

volumes:
  jupyter_data: